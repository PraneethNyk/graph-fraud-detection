{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"orig_nbformat":2,"kernelspec":{"name":"python3710jvsc74a57bd0563d867f513b1db22a50c0772d3498166496ad16228d7c1d495fd4c7e7a93ad6","display_name":"Python 3.7.10 64-bit ('graph': conda)"},"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"name":"20_modeling_pytoch.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0AICBHAJHa56","executionInfo":{"status":"ok","timestamp":1618961701295,"user_tz":300,"elapsed":250,"user":{"displayName":"Zekun Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh140SMb0c80XwwVdi_E7-Lh2XNkXKVWOakF5qL=s64","userId":"05904147758498762863"}},"outputId":"f768f31c-27c9-42c0-d25b-02cba3711798"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtJfGQ6GHh88","executionInfo":{"status":"ok","timestamp":1618961702360,"user_tz":300,"elapsed":386,"user":{"displayName":"Zekun Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh140SMb0c80XwwVdi_E7-Lh2XNkXKVWOakF5qL=s64","userId":"05904147758498762863"}},"outputId":"6c925799-505b-4ba9-c3ad-d3fcbb41e649"},"source":["import os\n","cur_path = \"/content/drive/MyDrive/graph-fraud-detection/\"\n","os.chdir(cur_path)\n","!pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/graph-fraud-detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aprSAaVaHiEX","executionInfo":{"status":"ok","timestamp":1618961706519,"user_tz":300,"elapsed":3361,"user":{"displayName":"Zekun Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh140SMb0c80XwwVdi_E7-Lh2XNkXKVWOakF5qL=s64","userId":"05904147758498762863"}},"outputId":"a1319f3f-ad65-4a0f-8a71-4bd75f758aef"},"source":["!pip install dgl\n","#-cu101"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: dgl in /usr/local/lib/python3.7/dist-packages (0.6.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.19.5)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.5.1)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6TREv-bfXKZ","executionInfo":{"status":"ok","timestamp":1618961711122,"user_tz":300,"elapsed":6350,"user":{"displayName":"Zekun Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh140SMb0c80XwwVdi_E7-Lh2XNkXKVWOakF5qL=s64","userId":"05904147758498762863"}},"outputId":"65b991e3-2c1f-4075-d144-f39933a8543a"},"source":["import os\n","import sys\n","\n","os.environ['DGLBACKEND'] = 'pytorch'\n","\n","import torch as th\n","import dgl\n","import numpy as np\n","import pandas as pd\n","import time\n","import pickle\n","\n","from sklearn.metrics import confusion_matrix\n","from gnn_fraud_detection_dgl.estimator_fns import *\n","from gnn_fraud_detection_dgl.graph_utils import *\n","from gnn_fraud_detection_dgl.data import *\n","from gnn_fraud_detection_dgl.utils import *\n","from gnn_fraud_detection_dgl.pytorch_model import *\n","from gnn_fraud_detection_dgl.fd_sl_train_entry_point import *"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using backend: pytorch\n"],"name":"stderr"},{"output_type":"stream","text":["DLG version: 0.6.1\n","DLG version: 0.6.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xFAJtIlAfXKZ","executionInfo":{"status":"ok","timestamp":1618961629036,"user_tz":300,"elapsed":512,"user":{"displayName":"Zekun Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh140SMb0c80XwwVdi_E7-Lh2XNkXKVWOakF5qL=s64","userId":"05904147758498762863"}}},"source":["def normalize(feature_matrix):\n","    mean = th.mean(feature_matrix, axis=0)\n","    stdev = th.sqrt(th.sum((feature_matrix - mean)**2, axis=0)/feature_matrix.shape[0])\n","    return mean, stdev, (feature_matrix - mean) / stdev\n","\n","\n","def train_fg(model, optim, loss, features, labels, train_g, test_g, test_mask,\n","             device, n_epochs, thresh, compute_metrics=True):\n","    \"\"\"\n","    A full graph verison of RGCN training\n","    \"\"\"\n","\n","    duration = []\n","    for epoch in range(n_epochs):\n","        tic = time.time()\n","        loss_val = 0.\n","\n","        pred = model(train_g, features.to(device))\n","\n","        l = loss(pred, labels)\n","\n","        optim.zero_grad()\n","        l.backward()\n","        optim.step()\n","\n","        loss_val += l\n","\n","        duration.append(time.time() - tic)\n","        metric = evaluate(model, train_g, features, labels, device)\n","        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | f1 {:.4f} \".format(\n","                epoch, np.mean(duration), loss_val, metric))\n","\n","    class_preds, pred_proba = get_model_class_predictions(model,\n","                                                          test_g,\n","                                                          features,\n","                                                          labels,\n","                                                          device,\n","                                                          threshold=thresh)\n","\n","    if compute_metrics:\n","        acc, f1, p, r, roc, pr, ap, cm = get_metrics(class_preds, pred_proba, labels.numpy(), test_mask.numpy(), './')\n","        print(\"Metrics\")\n","        print(\"\"\"Confusion Matrix:\n","                                {}\n","                                f1: {:.4f}, precision: {:.4f}, recall: {:.4f}, acc: {:.4f}, roc: {:.4f}, pr: {:.4f}, ap: {:.4f}\n","                             \"\"\".format(cm, f1, p, r, acc, roc, pr, ap))\n","\n","    return model, class_preds, pred_proba\n","\n","\n","def get_f1_score(y_true, y_pred):\n","    \"\"\"\n","    Only works for binary case.\n","    Attention!\n","    tn, fp, fn, tp = cf_m[0,0],cf_m[0,1],cf_m[1,0],cf_m[1,1]\n","\n","    :param y_true: A list of labels in 0 or 1: 1 * N\n","    :param y_pred: A list of labels in 0 or 1: 1 * N\n","    :return:\n","    \"\"\"\n","    # print(y_true, y_pred)\n","\n","    cf_m = confusion_matrix(y_true, y_pred)\n","    # print(cf_m)\n","\n","    precision = cf_m[1,1] / (cf_m[1,1] + cf_m[0,1] + 10e-5)\n","    recall = cf_m[1,1] / (cf_m[1,1] + cf_m[1,0])\n","    f1 = 2 * (precision * recall) / (precision + recall + 10e-5)\n","\n","    return precision, recall, f1\n","\n","\n","def evaluate(model, g, features, labels, device):\n","    \"Compute the F1 value in a binary classification case\"\n","\n","    preds = model(g, features.to(device))\n","    preds = th.argmax(preds, axis=1).numpy()\n","    precision, recall, f1 = get_f1_score(labels, preds)\n","\n","    return f1\n","\n","\n","def get_model_class_predictions(model, g, features, labels, device, threshold=None):\n","    unnormalized_preds = model(g, features.to(device))\n","    pred_proba = th.softmax(unnormalized_preds, dim=-1)\n","    if not threshold:\n","        return unnormalized_preds.argmax(axis=1).detach().numpy(), pred_proba[:,1].detach().numpy()\n","    return np.where(pred_proba.detach().numpy() > threshold, 1, 0), pred_proba[:,1].detach().numpy()\n","\n","\n","def save_model(g, model, model_dir, id_to_node, mean, stdev):\n","\n","    # Save Pytorch model's parameters to model.pth\n","    th.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n","\n","    # Save graph's structure information to metadata.pkl for inference codes to initialize RGCN model.\n","    etype_list = g.canonical_etypes\n","    ntype_cnt = {ntype: g.number_of_nodes(ntype) for ntype in g.ntypes}\n","    with open(os.path.join(model_dir, 'metadata.pkl'), 'wb') as f:\n","        pickle.dump({'etypes': etype_list,\n","                     'ntype_cnt': ntype_cnt,\n","                     'feat_mean': mean,\n","                     'feat_std': stdev}, f)\n","\n","    # Save original IDs to Node_ids, and trained embedding for non-target node type\n","    # Covert id_to_node into pandas dataframes\n","    for ntype, mapping in id_to_node.items():\n","\n","        # ignore target node\n","        if ntype == 'target':\n","            continue\n","\n","        # retrieve old and node id list\n","        old_id_list, node_id_list = [], []\n","        for old_id, node_id in mapping.items():\n","            old_id_list.append(old_id)\n","            node_id_list.append(node_id)\n","\n","        # retrieve embeddings of a node type\n","        node_feats = model.embed[ntype].detach().numpy()\n","\n","        # get the number of nodes and the dimension of features\n","        num_nodes = node_feats.shape[0]\n","        num_feats = node_feats.shape[1]\n","\n","        # create id dataframe\n","        node_ids_df = pd.DataFrame({'~label': [ntype] * num_nodes})\n","        node_ids_df['~id_tmp'] = old_id_list\n","        node_ids_df['~id'] = node_ids_df['~label'] + '-' + node_ids_df['~id_tmp']\n","        node_ids_df['node_id'] = node_id_list\n","\n","        # create feature dataframe columns\n","        cols = {'val' + str(i + 1) + ':Double': node_feats[:, i] for i in range(num_feats)}\n","        node_feats_df = pd.DataFrame(cols)\n","\n","        # merge id with feature, where feature_df use index\n","        node_id_feats_df = node_ids_df.merge(node_feats_df, left_on='node_id', right_on=node_feats_df.index)\n","        # drop the id_tmp and node_id columns to follow the Grelim format requirements\n","        node_id_feats_df = node_id_feats_df.drop(['~id_tmp', 'node_id'], axis=1)\n","\n","        # dump the embeddings to files\n","        node_id_feats_df.to_csv(os.path.join(model_dir, ntype + '.csv'),\n","                                index=False, header=True, encoding='utf-8')\n","\n","\n","def get_model(ntype_dict, etypes, hyperparams, in_feats, n_classes, device):\n","\n","    model = HeteroRGCN(ntype_dict, etypes, in_feats, hyperparams['n_hidden'], n_classes, hyperparams['n_layers'], in_feats)\n","    model = model.to(device)\n","\n","    return model"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9CmUjgaHXdj","executionInfo":{"status":"ok","timestamp":1618961631334,"user_tz":300,"elapsed":224,"user":{"displayName":"Zekun Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh140SMb0c80XwwVdi_E7-Lh2XNkXKVWOakF5qL=s64","userId":"05904147758498762863"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmqGrWm-HXdk","executionInfo":{"status":"ok","timestamp":1618961753110,"user_tz":300,"elapsed":287,"user":{"displayName":"Zekun Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh140SMb0c80XwwVdi_E7-Lh2XNkXKVWOakF5qL=s64","userId":"05904147758498762863"}}},"source":["import glob\n","\n","file_list = glob.glob('./data/*edgelist.csv')\n","\n","edges = \",\".join(map(lambda x: x.split(\"/\")[-1], [file for file in file_list if \"relation\" in file]))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGqAGRu-HXdm"},"source":["params = {'nodes' : 'features.csv',\n","          'edges': 'relation*',\n","          'labels': 'tags.csv',\n","          'embedding-size': 64,\n","          'n-layers': 2,\n","          'n-epochs': 10,\n","          'optimizer': 'adam',\n","          'lr': 1e-2\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWQp2MxLHXdo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa0dd6ef-b976-42a2-9cf4-ae458a02f3e8"},"source":["#logging = get_logger(__name__)\n","\n","print('numpy version:{} PyTorch version:{} DGL version:{}'.format(np.__version__,\n","                                                                    th.__version__,\n","                                                                    dgl.__version__))\n","\n","args = parse_args()\n","print(args)\n","args.edges = edges\n","\n","args.edges = get_edgelists('relation*', args.training_dir)\n","\n","g, features, target_id_to_node, id_to_node = construct_graph(args.training_dir,\n","                                                                args.edges,\n","                                                                args.nodes,\n","                                                                args.target_ntype)\n","\n","mean, stdev, features = normalize(th.from_numpy(features))\n","\n","print('feature mean shape:{}, std shape:{}'.format(mean.shape, stdev.shape))\n","\n","g.nodes['target'].data['features'] = features\n","\n","print(\"Getting labels\")\n","n_nodes = g.number_of_nodes('target')\n","\n","labels, _, test_mask = get_labels(target_id_to_node,\n","                                            n_nodes,\n","                                            args.target_ntype,\n","                                            os.path.join(args.training_dir, args.labels),\n","                                            os.path.join(args.training_dir, args.new_accounts))\n","print(\"Got labels\")\n","\n","labels = th.from_numpy(labels).float()\n","test_mask = th.from_numpy(test_mask).float()\n","\n","n_nodes = th.sum(th.tensor([g.number_of_nodes(n_type) for n_type in g.ntypes]))\n","n_edges = th.sum(th.tensor([g.number_of_edges(e_type) for e_type in g.etypes]))\n","\n","print(\"\"\"----Data statistics------'\n","            #Nodes: {}\n","            #Edges: {}\n","            #Features Shape: {}\n","            #Labeled Test samples: {}\"\"\".format(n_nodes,\n","                                                    n_edges,\n","                                                    features.shape,\n","                                                    test_mask.sum()))\n","\n","if args.num_gpus:\n","    cuda = True\n","    device = th.device('cuda:0')\n","else:\n","    cuda = False\n","    device = th.device('cpu')\n","\n","print(\"Initializing Model\")\n","in_feats = features.shape[1]\n","n_classes = 2\n","\n","ntype_dict = {n_type: g.number_of_nodes(n_type) for n_type in g.ntypes}\n","\n","model = get_model(ntype_dict, g.etypes, vars(args), in_feats, n_classes, device)\n","print(\"Initialized Model\")\n","\n","features = features.to(device)\n","\n","labels = labels.long().to(device)\n","test_mask = test_mask.to(device)\n","# g = g.to(device)\n","\n","loss = th.nn.CrossEntropyLoss()\n","\n","# print(model)\n","optim = th.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n","\n","print(\"Starting Model training\")\n","model, class_preds, pred_proba = train_fg(model, optim, loss, features, labels, g, g,\n","                                            test_mask, device, args.n_epochs,\n","                                            args.threshold,  args.compute_metrics)\n","print(\"Finished Model training\")\n","\n","print(\"Saving model\")\n","save_model(g, model, args.model_dir, id_to_node, mean, stdev)\n","print(\"Model and metadata saved\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["numpy version:1.19.5 PyTorch version:1.8.1+cu101 DGL version:0.6.1\n","Namespace(compute_metrics=True, dropout=0.2, edges='relation*', embedding_size=360, labels='tags.csv', lr=0.01, model_dir='./model/2021_04_20_23_36_08', n_epochs=200, n_hidden=16, n_layers=3, new_accounts='test.csv', nodes='features.csv', num_gpus=0, optimizer='adam', output_dir='./output', target_ntype='TransactionID', threshold=0, training_dir='./data', weight_decay=0.0005)\n","Getting relation graphs from the following edge lists : ['relation_card1_edgelist.csv', 'relation_card2_edgelist.csv', 'relation_card4_edgelist.csv', 'relation_card3_edgelist.csv', 'relation_card5_edgelist.csv', 'relation_ProductCD_edgelist.csv', 'relation_card6_edgelist.csv', 'relation_addr1_edgelist.csv', 'relation_addr2_edgelist.csv', 'relation_P_emaildomain_edgelist.csv', 'relation_R_emaildomain_edgelist.csv', 'relation_id_02_edgelist.csv', 'relation_id_01_edgelist.csv', 'relation_id_03_edgelist.csv', 'relation_TransactionID_edgelist.csv', 'relation_id_07_edgelist.csv', 'relation_id_05_edgelist.csv', 'relation_id_04_edgelist.csv', 'relation_id_06_edgelist.csv', 'relation_id_09_edgelist.csv', 'relation_id_08_edgelist.csv', 'relation_id_10_edgelist.csv', 'relation_id_14_edgelist.csv', 'relation_id_13_edgelist.csv', 'relation_id_11_edgelist.csv', 'relation_id_12_edgelist.csv', 'relation_id_15_edgelist.csv', 'relation_id_18_edgelist.csv', 'relation_id_22_edgelist.csv', 'relation_id_21_edgelist.csv', 'relation_id_16_edgelist.csv', 'relation_id_17_edgelist.csv', 'relation_id_19_edgelist.csv', 'relation_id_20_edgelist.csv', 'relation_id_30_edgelist.csv', 'relation_id_32_edgelist.csv', 'relation_id_25_edgelist.csv', 'relation_id_29_edgelist.csv', 'relation_id_24_edgelist.csv', 'relation_id_27_edgelist.csv', 'relation_id_28_edgelist.csv', 'relation_id_26_edgelist.csv', 'relation_id_23_edgelist.csv', 'relation_id_31_edgelist.csv', 'relation_id_37_edgelist.csv', 'relation_id_35_edgelist.csv', 'relation_id_36_edgelist.csv', 'relation_id_34_edgelist.csv', 'relation_id_33_edgelist.csv', 'relation_DeviceType_edgelist.csv', 'relation_DeviceInfo_edgelist.csv', 'relation_id_38_edgelist.csv'] \n","Read edges for target<card1> from edgelist: ./data/relation_card1_edgelist.csv\n","Read edges for target<card2> from edgelist: ./data/relation_card2_edgelist.csv\n","Read edges for target<card4> from edgelist: ./data/relation_card4_edgelist.csv\n","Read edges for target<card3> from edgelist: ./data/relation_card3_edgelist.csv\n","Read edges for target<card5> from edgelist: ./data/relation_card5_edgelist.csv\n","Read edges for target<ProductCD> from edgelist: ./data/relation_ProductCD_edgelist.csv\n","Read edges for target<card6> from edgelist: ./data/relation_card6_edgelist.csv\n","Read edges for target<addr1> from edgelist: ./data/relation_addr1_edgelist.csv\n","Read edges for target<addr2> from edgelist: ./data/relation_addr2_edgelist.csv\n","Read edges for target<P_emaildomain> from edgelist: ./data/relation_P_emaildomain_edgelist.csv\n","Read edges for target<R_emaildomain> from edgelist: ./data/relation_R_emaildomain_edgelist.csv\n","Read edges for target<id_02> from edgelist: ./data/relation_id_02_edgelist.csv\n","Read edges for target<id_01> from edgelist: ./data/relation_id_01_edgelist.csv\n","Read edges for target<id_03> from edgelist: ./data/relation_id_03_edgelist.csv\n","Will add self loop for target later......\n","Read edges for target<id_07> from edgelist: ./data/relation_id_07_edgelist.csv\n","Read edges for target<id_05> from edgelist: ./data/relation_id_05_edgelist.csv\n","Read edges for target<id_04> from edgelist: ./data/relation_id_04_edgelist.csv\n","Read edges for target<id_06> from edgelist: ./data/relation_id_06_edgelist.csv\n","Read edges for target<id_09> from edgelist: ./data/relation_id_09_edgelist.csv\n","Read edges for target<id_08> from edgelist: ./data/relation_id_08_edgelist.csv\n","Read edges for target<id_10> from edgelist: ./data/relation_id_10_edgelist.csv\n","Read edges for target<id_14> from edgelist: ./data/relation_id_14_edgelist.csv\n","Read edges for target<id_13> from edgelist: ./data/relation_id_13_edgelist.csv\n","Read edges for target<id_11> from edgelist: ./data/relation_id_11_edgelist.csv\n","Read edges for target<id_12> from edgelist: ./data/relation_id_12_edgelist.csv\n","Read edges for target<id_15> from edgelist: ./data/relation_id_15_edgelist.csv\n","Read edges for target<id_18> from edgelist: ./data/relation_id_18_edgelist.csv\n","Read edges for target<id_22> from edgelist: ./data/relation_id_22_edgelist.csv\n","Read edges for target<id_21> from edgelist: ./data/relation_id_21_edgelist.csv\n","Read edges for target<id_16> from edgelist: ./data/relation_id_16_edgelist.csv\n","Read edges for target<id_17> from edgelist: ./data/relation_id_17_edgelist.csv\n","Read edges for target<id_19> from edgelist: ./data/relation_id_19_edgelist.csv\n","Read edges for target<id_20> from edgelist: ./data/relation_id_20_edgelist.csv\n","Read edges for target<id_30> from edgelist: ./data/relation_id_30_edgelist.csv\n","Read edges for target<id_32> from edgelist: ./data/relation_id_32_edgelist.csv\n","Read edges for target<id_25> from edgelist: ./data/relation_id_25_edgelist.csv\n","Read edges for target<id_29> from edgelist: ./data/relation_id_29_edgelist.csv\n","Read edges for target<id_24> from edgelist: ./data/relation_id_24_edgelist.csv\n","Read edges for target<id_27> from edgelist: ./data/relation_id_27_edgelist.csv\n","Read edges for target<id_28> from edgelist: ./data/relation_id_28_edgelist.csv\n","Read edges for target<id_26> from edgelist: ./data/relation_id_26_edgelist.csv\n","Read edges for target<id_23> from edgelist: ./data/relation_id_23_edgelist.csv\n","Read edges for target<id_31> from edgelist: ./data/relation_id_31_edgelist.csv\n","Read edges for target<id_37> from edgelist: ./data/relation_id_37_edgelist.csv\n","Read edges for target<id_35> from edgelist: ./data/relation_id_35_edgelist.csv\n","Read edges for target<id_36> from edgelist: ./data/relation_id_36_edgelist.csv\n","Read edges for target<id_34> from edgelist: ./data/relation_id_34_edgelist.csv\n","Read edges for target<id_33> from edgelist: ./data/relation_id_33_edgelist.csv\n","Read edges for target<DeviceType> from edgelist: ./data/relation_DeviceType_edgelist.csv\n","Read edges for target<DeviceInfo> from edgelist: ./data/relation_DeviceInfo_edgelist.csv\n","Read edges for target<id_38> from edgelist: ./data/relation_id_38_edgelist.csv\n","Read in features for target nodes\n","Constructed heterograph with the following metagraph structure: Node types ['DeviceInfo', 'DeviceType', 'P_emaildomain', 'ProductCD', 'R_emaildomain', 'addr1', 'addr2', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'target'], Edge types[('DeviceInfo', 'DeviceInfo<>target', 'target'), ('DeviceType', 'DeviceType<>target', 'target'), ('P_emaildomain', 'P_emaildomain<>target', 'target'), ('ProductCD', 'ProductCD<>target', 'target'), ('R_emaildomain', 'R_emaildomain<>target', 'target'), ('addr1', 'addr1<>target', 'target'), ('addr2', 'addr2<>target', 'target'), ('card1', 'card1<>target', 'target'), ('card2', 'card2<>target', 'target'), ('card3', 'card3<>target', 'target'), ('card4', 'card4<>target', 'target'), ('card5', 'card5<>target', 'target'), ('card6', 'card6<>target', 'target'), ('id_01', 'id_01<>target', 'target'), ('id_02', 'id_02<>target', 'target'), ('id_03', 'id_03<>target', 'target'), ('id_04', 'id_04<>target', 'target'), ('id_05', 'id_05<>target', 'target'), ('id_06', 'id_06<>target', 'target'), ('id_07', 'id_07<>target', 'target'), ('id_08', 'id_08<>target', 'target'), ('id_09', 'id_09<>target', 'target'), ('id_10', 'id_10<>target', 'target'), ('id_11', 'id_11<>target', 'target'), ('id_12', 'id_12<>target', 'target'), ('id_13', 'id_13<>target', 'target'), ('id_14', 'id_14<>target', 'target'), ('id_15', 'id_15<>target', 'target'), ('id_16', 'id_16<>target', 'target'), ('id_17', 'id_17<>target', 'target'), ('id_18', 'id_18<>target', 'target'), ('id_19', 'id_19<>target', 'target'), ('id_20', 'id_20<>target', 'target'), ('id_21', 'id_21<>target', 'target'), ('id_22', 'id_22<>target', 'target'), ('id_23', 'id_23<>target', 'target'), ('id_24', 'id_24<>target', 'target'), ('id_25', 'id_25<>target', 'target'), ('id_26', 'id_26<>target', 'target'), ('id_27', 'id_27<>target', 'target'), ('id_28', 'id_28<>target', 'target'), ('id_29', 'id_29<>target', 'target'), ('id_30', 'id_30<>target', 'target'), ('id_31', 'id_31<>target', 'target'), ('id_32', 'id_32<>target', 'target'), ('id_33', 'id_33<>target', 'target'), ('id_34', 'id_34<>target', 'target'), ('id_35', 'id_35<>target', 'target'), ('id_36', 'id_36<>target', 'target'), ('id_37', 'id_37<>target', 'target'), ('id_38', 'id_38<>target', 'target'), ('target', 'self_relation', 'target'), ('target', 'target<>DeviceInfo', 'DeviceInfo'), ('target', 'target<>DeviceType', 'DeviceType'), ('target', 'target<>P_emaildomain', 'P_emaildomain'), ('target', 'target<>ProductCD', 'ProductCD'), ('target', 'target<>R_emaildomain', 'R_emaildomain'), ('target', 'target<>addr1', 'addr1'), ('target', 'target<>addr2', 'addr2'), ('target', 'target<>card1', 'card1'), ('target', 'target<>card2', 'card2'), ('target', 'target<>card3', 'card3'), ('target', 'target<>card4', 'card4'), ('target', 'target<>card5', 'card5'), ('target', 'target<>card6', 'card6'), ('target', 'target<>id_01', 'id_01'), ('target', 'target<>id_02', 'id_02'), ('target', 'target<>id_03', 'id_03'), ('target', 'target<>id_04', 'id_04'), ('target', 'target<>id_05', 'id_05'), ('target', 'target<>id_06', 'id_06'), ('target', 'target<>id_07', 'id_07'), ('target', 'target<>id_08', 'id_08'), ('target', 'target<>id_09', 'id_09'), ('target', 'target<>id_10', 'id_10'), ('target', 'target<>id_11', 'id_11'), ('target', 'target<>id_12', 'id_12'), ('target', 'target<>id_13', 'id_13'), ('target', 'target<>id_14', 'id_14'), ('target', 'target<>id_15', 'id_15'), ('target', 'target<>id_16', 'id_16'), ('target', 'target<>id_17', 'id_17'), ('target', 'target<>id_18', 'id_18'), ('target', 'target<>id_19', 'id_19'), ('target', 'target<>id_20', 'id_20'), ('target', 'target<>id_21', 'id_21'), ('target', 'target<>id_22', 'id_22'), ('target', 'target<>id_23', 'id_23'), ('target', 'target<>id_24', 'id_24'), ('target', 'target<>id_25', 'id_25'), ('target', 'target<>id_26', 'id_26'), ('target', 'target<>id_27', 'id_27'), ('target', 'target<>id_28', 'id_28'), ('target', 'target<>id_29', 'id_29'), ('target', 'target<>id_30', 'id_30'), ('target', 'target<>id_31', 'id_31'), ('target', 'target<>id_32', 'id_32'), ('target', 'target<>id_33', 'id_33'), ('target', 'target<>id_34', 'id_34'), ('target', 'target<>id_35', 'id_35'), ('target', 'target<>id_36', 'id_36'), ('target', 'target<>id_37', 'id_37'), ('target', 'target<>id_38', 'id_38')]\n","Number of nodes of type target : 590540\n","<class 'torch.Tensor'>\n","feature mean shape:torch.Size([390]), std shape:torch.Size([390])\n","Getting labels\n","Got labels\n","----Data statistics------'\n","            #Nodes: 726345\n","            #Edges: 19518802\n","            #Features Shape: torch.Size([590540, 390])\n","            #Labeled Test samples: 413378.0\n","Initializing Model\n","Initialized Model\n","Starting Model training\n","Epoch 00000 | Time(s) 37.6330 | Loss 0.6200 | f1 0.0000 \n","Epoch 00001 | Time(s) 34.2110 | Loss 0.8080 | f1 0.0000 \n","Epoch 00002 | Time(s) 32.5294 | Loss 0.4223 | f1 0.0084 \n","Epoch 00003 | Time(s) 31.5734 | Loss 0.1643 | f1 0.1389 \n","Epoch 00004 | Time(s) 31.1140 | Loss 1.0433 | f1 0.0000 \n","Epoch 00005 | Time(s) 30.7612 | Loss 0.1482 | f1 0.0000 \n","Epoch 00006 | Time(s) 30.6265 | Loss 0.1926 | f1 0.0000 \n","Epoch 00007 | Time(s) 30.5723 | Loss 0.2064 | f1 0.0000 \n","Epoch 00008 | Time(s) 30.4763 | Loss 0.1973 | f1 0.0000 \n","Epoch 00009 | Time(s) 31.4182 | Loss 0.1764 | f1 0.0000 \n","Epoch 00010 | Time(s) 31.3743 | Loss 0.1558 | f1 0.0000 \n","Epoch 00011 | Time(s) 31.2770 | Loss 0.1508 | f1 0.0000 \n","Epoch 00012 | Time(s) 31.2907 | Loss 0.1561 | f1 0.0000 \n","Epoch 00013 | Time(s) 31.2057 | Loss 0.1545 | f1 0.0007 \n","Epoch 00014 | Time(s) 31.2447 | Loss 0.1465 | f1 0.0011 \n","Epoch 00015 | Time(s) 31.4665 | Loss 0.1406 | f1 0.0013 \n","Epoch 00016 | Time(s) 31.4783 | Loss 0.1405 | f1 0.0015 \n","Epoch 00017 | Time(s) 31.4428 | Loss 0.1434 | f1 0.0017 \n","Epoch 00018 | Time(s) 31.4195 | Loss 0.1449 | f1 0.0050 \n","Epoch 00019 | Time(s) 31.3579 | Loss 0.1429 | f1 0.0113 \n","Epoch 00020 | Time(s) 31.3595 | Loss 0.1391 | f1 0.0262 \n","Epoch 00021 | Time(s) 31.3919 | Loss 0.1369 | f1 0.0322 \n","Epoch 00022 | Time(s) 31.4219 | Loss 0.1353 | f1 0.0298 \n","Epoch 00023 | Time(s) 31.6036 | Loss 0.1344 | f1 0.0304 \n","Epoch 00024 | Time(s) 31.6577 | Loss 0.1349 | f1 0.0426 \n","Epoch 00025 | Time(s) 31.7383 | Loss 0.1344 | f1 0.0688 \n","Epoch 00026 | Time(s) 31.7782 | Loss 0.1320 | f1 0.0981 \n","Epoch 00027 | Time(s) 31.8263 | Loss 0.1309 | f1 0.1157 \n","Epoch 00028 | Time(s) 31.8787 | Loss 0.1298 | f1 0.1104 \n","Epoch 00029 | Time(s) 31.8825 | Loss 0.1286 | f1 0.1108 \n","Epoch 00030 | Time(s) 31.8651 | Loss 0.1284 | f1 0.1275 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Asfws7O3oZLb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-u3-n_xdoZLc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JTmmYlyoZLc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUaiLCITHXdo"},"source":[""],"execution_count":null,"outputs":[]}]}